{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d620382-cb03-4a56-bba8-01e0adf2c3f6",
   "metadata": {},
   "source": [
    "# BIRD SOUND CLASSIFICATION - COMPLETE ML PIPELINE\n",
    "### African Leadership University - Machine Learning Pipeline Assignment\n",
    "\n",
    "# Date: November 2024\n",
    "####  ML pipeline for audio classification\n",
    "\n",
    "\n",
    "#### ðŸ¦ Bird Sound Classification - Complete ML Pipeline\n",
    "\n",
    "## Table of Contents\n",
    "1. Exploratory Data Analysis \n",
    "2. Audio Feature Visualization\n",
    "3. Data Preprocessing and Feature Extraction\n",
    "4. Feature Analysis and Interpretations \n",
    "5. Train-Test Split Strategy\n",
    "6. Model Architecture and Training\n",
    "7. Model Evaluation and Metrics \n",
    "8. Error Analysis\n",
    "9. Model Deployment Preparation\n",
    "10. Conclusions and Future Work\n",
    "\n",
    "#### Project Overview\n",
    "This notebook implements a complete machine learning pipeline for classifying \n",
    "64 bird species based on audio recordings. We extract 95 acoustic features \n",
    "and train a deep neural network to achieve high accuracy classification.\n",
    "\n",
    "**Key Features:**\n",
    "- 64 bird species classification\n",
    "- 95 audio features \n",
    "- Deep Neural Network \n",
    "- Production-ready model deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76cdf9-0f72-4495-a624-acfe35ba33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
    "                            precision_recall_fscore_support, f1_score,\n",
    "                            precision_score, recall_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__} | GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340235d-d368-4af2-a0b0-a0075730a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOAD DATASET\n",
    "\n",
    "def load_dataset(csv_path):\n",
    "    \"\"\"Load dataset from CSV and extract temporal features\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['year'] = df['Date'].apply(lambda x: str(x).split('-')[0])\n",
    "    df['month'] = df['Date'].apply(lambda x: str(x).split('-')[1])\n",
    "    df['day_of_month'] = df['Date'].apply(lambda x: str(x).split('-')[2])\n",
    "    \n",
    "    print(\"DATASET LOADED\")\n",
    "    print(f\"Shape: {df.shape} | Species: {df['common_name'].nunique()}\")\n",
    "    return df\n",
    "\n",
    "# UPDATE WITH YOUR CSV PATH\n",
    "CSV_PATH = r\"C:\\Users\\PC\\Desktop\\assignment---MLOP\\audio_processing_fe_bird_sounds\\data\\raw\\Birds Voice.csv\"\n",
    "train_csv = load_dataset(CSV_PATH)\n",
    "\n",
    "print(train_csv.head())\n",
    "print(f\"\\nColumns: {train_csv.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0dd1a-e3a8-4ffb-8105-21dc00363fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  AUDIO PROCESSING FUNCTIONS\n",
    "\n",
    "def load_and_trim_audio(file_path, sr=22050, top_db=23):\n",
    "    \"\"\"Load and trim silence from audio file\"\"\"\n",
    "    try:\n",
    "        data, sample_rate = librosa.load(file_path, sr=sr)\n",
    "        trimmed_data, _ = librosa.effects.trim(data, top_db=top_db)\n",
    "        return trimmed_data, sample_rate\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "def extract_features(audio_data, sr=22050):\n",
    "    \"\"\"Extract 95 audio features WITHOUT fitting any scalers\"\"\"\n",
    "    if audio_data is None or len(audio_data) == 0:\n",
    "        return None\n",
    "    try:\n",
    "        features = []\n",
    "        \n",
    "        # MFCC \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=20)\n",
    "        features.extend(np.mean(mfccs, axis=1))\n",
    "        features.extend(np.std(mfccs, axis=1))\n",
    "        features.extend(np.max(mfccs, axis=1))\n",
    "        features.extend(np.min(mfccs, axis=1))\n",
    "        \n",
    "        # Spectral features\n",
    "        sc = librosa.feature.spectral_centroid(y=audio_data, sr=sr)\n",
    "        features.extend([np.mean(sc), np.std(sc), np.max(sc)])\n",
    "        \n",
    "        sr_off = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)\n",
    "        features.extend([np.mean(sr_off), np.std(sr_off)])\n",
    "        \n",
    "        zcr = librosa.feature.zero_crossing_rate(audio_data)\n",
    "        features.extend([np.mean(zcr), np.std(zcr)])\n",
    "        \n",
    "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)\n",
    "        features.extend([np.mean(chroma), np.std(chroma)])\n",
    "        \n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio_data, sr=sr, n_mels=128)\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        features.extend([np.mean(mel_db), np.std(mel_db), np.max(mel_db)])\n",
    "        \n",
    "        sbw = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)\n",
    "        features.extend([np.mean(sbw), np.std(sbw)])\n",
    "        \n",
    "        rms = librosa.feature.rms(y=audio_data)\n",
    "        features.append(np.mean(rms))\n",
    "        \n",
    "        return np.array(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Feature extraction error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5933da8-a2e7-42c3-a148-e58f1005062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS AUDIO FILES\n",
    "\n",
    "AUDIO_BASE_PATH = r\"C:\\Users\\PC\\Desktop\\assignment---MLOP\\audio_processing_fe_bird_sounds\\data\\Voice of Birds\\Voice of Birds\"\n",
    "\n",
    "def process_dataset_with_unique_samples(df, audio_base_path, samples_per_species=20, min_samples_per_class=15):\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    file_paths_list = []\n",
    "    \n",
    "    species_counts = df['common_name'].value_counts()\n",
    "    valid_species = species_counts[species_counts >= min_samples_per_class].index\n",
    "    \n",
    "    print(f\"Processing {len(valid_species)} species with >= {min_samples_per_class} samples each\")\n",
    "    \n",
    "    available_folders = os.listdir(audio_base_path)\n",
    "    \n",
    "    def find_species_folder(common_name):\n",
    "        for folder in available_folders:\n",
    "            folder_clean = folder.lower().replace('_', ' ').replace('sound', '').strip()\n",
    "            if common_name.lower() in folder_clean or folder_clean in common_name.lower():\n",
    "                return folder\n",
    "        return None\n",
    "    \n",
    "    for species in tqdm(valid_species, desc=\"Processing species\"):\n",
    "        species_folder = find_species_folder(species)\n",
    "        if not species_folder:\n",
    "            continue\n",
    "        \n",
    "        folder_path = os.path.join(audio_base_path, species_folder)\n",
    "        mp3_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.mp3')]\n",
    "        \n",
    "        if len(mp3_files) == 0:\n",
    "            continue\n",
    "        \n",
    "        np.random.shuffle(mp3_files)\n",
    "        files_to_process = mp3_files[:samples_per_species]\n",
    "        \n",
    "        for mp3_file in files_to_process:\n",
    "            try:\n",
    "                file_path = os.path.join(folder_path, mp3_file)\n",
    "                audio_data, sr = load_and_trim_audio(file_path)\n",
    "                \n",
    "                if audio_data is None or len(audio_data) < sr * 0.5:\n",
    "                    continue\n",
    "                \n",
    "                features = extract_features(audio_data, sr)\n",
    "                if features is None or np.isnan(features).any():\n",
    "                    continue\n",
    "                \n",
    "                features_list.append(features)\n",
    "                labels_list.append(species)\n",
    "                file_paths_list.append(file_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nProcessed: {len(features_list)} samples from {len(np.unique(labels_list))} species\")\n",
    "    return np.array(features_list), np.array(labels_list), file_paths_list\n",
    "\n",
    "X, y, file_paths = process_dataset_with_unique_samples(\n",
    "    train_csv, AUDIO_BASE_PATH, samples_per_species=25, min_samples_per_class=15\n",
    ")\n",
    "\n",
    "print(f\"Raw Features: {X.shape} | Labels: {y.shape}\")\n",
    "print(f\"Unique species: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbc0e8-1411-473e-bdb7-a097dc820c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TRAIN and TEST SPLIT & SCALING \n",
    "\n",
    "# CRITICAL: Encode and split BEFORE scaling\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=RANDOM_SEED, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Data split BEFORE scaling\")\n",
    "print(f\"  Train: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "y_train = to_categorical(y_train_encoded)\n",
    "y_test = to_categorical(y_test_encoded)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nScaling applied correctly\")\n",
    "print(f\"  Train mean: {X_train_scaled.mean():.6f}, std: {X_train_scaled.std():.6f}\")\n",
    "print(f\"  Test mean: {X_test_scaled.mean():.6f}, std: {X_test_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4bca6b-529e-4d9f-bc01-db8038cdf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAVE DATA\n",
    "\n",
    "base_path = r\"C:\\Users\\PC\\Desktop\\assignment---MLOP\\audio_processing_fe_bird_sounds\\data\"\n",
    "train_path = os.path.join(base_path, \"train\")\n",
    "test_path = os.path.join(base_path, \"test\")\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(train_path, \"X_train.npy\"), X_train_scaled)\n",
    "np.save(os.path.join(train_path, \"y_train.npy\"), y_train_encoded)\n",
    "np.save(os.path.join(test_path, \"X_test.npy\"), X_test_scaled)\n",
    "np.save(os.path.join(test_path, \"y_test.npy\"), y_test_encoded)\n",
    "\n",
    "print(\"Train and test sets saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51aa43-ac69-4924-9c20-753c630bad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  BUILD MODEL ARCHITECTURE\n",
    "\n",
    "\n",
    "def create_optimized_model(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_optimized_model(X_train_scaled.shape[1], y_train.shape[1])\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe75071-0941-4696-978b-3b6ccacb1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint('models/best_model.h5', monitor='val_accuracy', \n",
    "                   save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, \n",
    "                     min_lr=0.00001, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"TRAINING MODEL\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190439fa-7746-4903-8cc8-d90a59b09690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PLOT TRAINING HISTORY\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Training History', fontsize=20, fontweight='bold')\n",
    "\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Val', linewidth=2)\n",
    "axes[0, 0].set_title('Accuracy'); axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Val', linewidth=2)\n",
    "axes[0, 1].set_title('Loss'); axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Val', linewidth=2)\n",
    "axes[1, 0].set_title('Precision'); axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Val', linewidth=2)\n",
    "axes[1, 1].set_title('Recall'); axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276511a-2216-42b5-b1bf-ba77bb33bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE MODEL\n",
    "\n",
    "\n",
    "print(\"MODEL EVALUATION ON TEST SET\")\n",
    "\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "test_loss = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(\"PERFORMANCE METRICS (4+ Required)\")\n",
    "print(f\"1. ACCURACY:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"2. PRECISION: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"3. RECALL:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"4. F1-SCORE:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "print(f\"5. TEST LOSS: {test_loss[0]:.4f}\")\n",
    "\n",
    "if accuracy > 0.95:\n",
    "    print(\"\\nWARNING: Very high accuracy - check for overfitting\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Realistic accuracy indicates proper train/test separation\")\n",
    "\n",
    "print(\"\\nDETAILED CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb534133-0788-4047-8058-a261b15f0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CONFUSION MATRIX\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
